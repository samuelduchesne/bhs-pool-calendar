name: Publish EKAC lanes calendar

on:
  schedule:
    - cron: "10 9 * * *"   # ~05:10 ET daily (UTC-based)
  workflow_dispatch: {}

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Write scraper script
        run: |
          mkdir -p app public
          cat > app/build_calendar.py <<'PY'
          #!/usr/bin/env python3
          from __future__ import annotations

          import hashlib
          import io
          import os
          import re
          import sys
          from dataclasses import dataclass
          from datetime import datetime, timedelta, timezone
          from typing import Iterable, List, Tuple

          import pdfplumber
          import requests
          from bs4 import BeautifulSoup
          from dateutil import parser as dtparse
          from icalendar import Calendar, Event

          AQUATICS_URL = "https://www.brooklinerec.com/150/Aquatics-Center"
          FALLBACK_PDF = "https://www.brooklinerec.com/DocumentCenter/View/4404/Pool-Schedule?bidId="
          DAYS = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]

          @dataclass(frozen=True)
          class Block:
              start: datetime  # UTC
              end: datetime    # UTC
              lanes_label: str
              source_url: str

          def discover_latest_pdf() -> str:
              try:
                  resp = requests.get(AQUATICS_URL, timeout=30)
                  resp.raise_for_status()
                  soup = BeautifulSoup(resp.text, "html.parser")
                  for a in soup.find_all("a", href=True):
                      href = a["href"]
                      text = (a.get_text() or "").lower()
                      if ("/DocumentCenter/View/" in href) and ("pool" in text and "schedule" in text):
                          return requests.compat.urljoin(AQUATICS_URL, href)
                  for a in soup.find_all("a", href=True):
                      href = a["href"]
                      if "/DocumentCenter/View/" in href and "Pool" in href and "Schedule" in href:
                          return requests.compat.urljoin(AQUATICS_URL, href)
              except Exception:
                  pass
              return FALLBACK_PDF

          def month_span_to_dates(header: str, now_utc: datetime) -> Tuple[datetime, datetime]:
              m = re.search(r"Pool Schedule for\s+([A-Za-z]+)\s+(\d{1,2})\s*-\s*(\d{1,2})", header)
              if not m:
                  raise ValueError(f"Unrecognized header line: {header!r}")
              month, d1, d2 = m.group(1), int(m.group(2)), int(m.group(3))
              candidates = []
              for year in (now_utc.year - 1, now_utc.year, now_utc.year + 1):
                  s = dtparse.parse(f"{month} {d1}, {year}").date()
                  e = dtparse.parse(f"{month} {d2}, {year}").date()
                  candidates.append((s, e, abs((now_utc.date() - s).days)))
              s, e, _ = min(candidates, key=lambda t: t[2])
              return (
                  datetime(s.year, s.month, s.day, tzinfo=timezone.utc),
                  datetime(e.year, e.month, e.day, tzinfo=timezone.utc),
              )

          def to_utc_local_eastern(local_date: datetime, hh: int, mm: int) -> datetime:
              from zoneinfo import ZoneInfo
              eastern = ZoneInfo("America/New_York")
              local_dt = datetime(local_date.year, local_date.month, local_date.day, hh, mm, tzinfo=eastern)
              return local_dt.astimezone(timezone.utc)

          def time_token_to_24h(tstr: str) -> tuple[int, int]:
              """Parse times like '7a', '7 am', '7:15a', '7:15 am', '7pm', '7:15pm'."""
              s = tstr.strip().lower().replace(" ", "")
              m = re.fullmatch(r"(\d{1,2})(?::(\d{2}))?(a|p|am|pm)", s)
              if not m:
                  raise ValueError(f"Bad time token: {tstr}")
              hh = int(m.group(1))
              mm = int(m.group(2) or 0)
              ap = m.group(3)
              if ap.startswith("a"):
                  hh = 0 if hh == 12 else hh
              else:
                  hh = 12 if hh == 12 else hh + 12
              return hh, mm

          def group_by_day_columns(words: list[dict]) -> dict[str, list[dict]]:
              name_map = {
                  "monday": "Monday", "mon": "Monday",
                  "tuesday": "Tuesday", "tue": "Tuesday", "tues": "Tuesday",
                  "wednesday": "Wednesday", "wed": "Wednesday",
                  "thursday": "Thursday", "thu": "Thursday", "thur": "Thursday", "thurs": "Thursday",
                  "friday": "Friday", "fri": "Friday",
                  "saturday": "Saturday", "sat": "Saturday",
                  "sunday": "Sunday", "sun": "Sunday",
              }
              headers: list[tuple[str, float]] = []
              for w in words:
                  key = name_map.get(w["text"].strip().lower())
                  if key:
                      headers.append((key, (w["x0"] + w["x1"]) / 2.0))
              # take the leftmost instance of each weekday to avoid duplicate matches
              best: dict[str, float] = {}
              for name, xmid in sorted(headers, key=lambda t: t[1]):
                  if name not in best:
                      best[name] = xmid
              if len(best) < 7:
                  raise ValueError("Failed to find weekday headers")
          
              ordered = [("Monday", best["Monday"]), ("Tuesday", best["Tuesday"]), ("Wednesday", best["Wednesday"]),
                         ("Thursday", best["Thursday"]), ("Friday", best["Friday"]), ("Saturday", best["Saturday"]),
                         ("Sunday", best["Sunday"])]
          
              bounds: list[tuple[str, float, float]] = []
              for i, (day, xmid) in enumerate(ordered):
                  left = -1e9 if i == 0 else (ordered[i - 1][1] + xmid) / 2.0
                  right = 1e9 if i == 6 else (xmid + ordered[i + 1][1]) / 2.0
                  bounds.append((day, left, right))
          
              columns: dict[str, list[dict]] = {d: [] for d, _ in ordered}
              for w in words:
                  xmid = (w["x0"] + w["x1"]) / 2.0
                  for day, left, right in bounds:
                      if left <= xmid <= right:
                          columns[day].append(w)
                          break
              for d in columns:
                  columns[d].sort(key=lambda w: (w["top"], w["x0"]))
              return columns

          def _rows_from_words(day_words: list[dict], tol: float = 3.5) -> list[list[dict]]:
              """Cluster tokens into visual rows by y ('top') with a tolerance."""
              if not day_words:
                  return []
              ws = sorted(day_words, key=lambda w: (w["top"], w["x0"]))
              rows: list[list[dict]] = []
              cur: list[dict] = [ws[0]]
              cur_y = ws[0]["top"]
              for w in ws[1:]:
                  if abs(w["top"] - cur_y) <= tol:
                      cur.append(w)
                  else:
                      rows.append(cur)
                      cur = [w]
                      cur_y = w["top"]
              rows.append(cur)
              # sort each row left→right
              for r in rows:
                  r.sort(key=lambda w: w["x0"])
              return rows

          def extract_blocks_for_day(day_words: list[dict], local_date: datetime) -> Iterable[tuple[datetime, datetime, str]]:
              # Time range: allow spaces, optional minutes, hyphen/en-dash, a/p/am/pm
              time_re = re.compile(
                  r"(?P<s>\d{1,2}(?::\d{2})?\s*(?:a|p|am|pm))\s*[-–]\s*(?P<e>\d{1,2}(?::\d{2})?\s*(?:a|p|am|pm))",
                  re.IGNORECASE,
              )
              # Lanes: "5", "4-5", "4–5", with optional 'lane(s)' noise around it
              lanes_re = re.compile(
                  r"(?:^|\D)(?P<n1>\d{1,2})(?:\s*[–-]\s*(?P<n2>\d{1,2}))?(?:\D|$)",
                  re.IGNORECASE,
              )
          
              for row in _rows_from_words(day_words):
                  row_text = " ".join(w["text"] for w in row)
                  m = time_re.search(row_text)
                  if not m:
                      continue
                  # prefer a lanes number that appears *after* the time range in the same row
                  lanes = None
                  for m2 in lanes_re.finditer(row_text[m.end():]):
                      n1 = int(m2.group("n1"))
                      n2 = m2.group("n2")
                      lanes = f"{n1}–{int(n2)}" if n2 else f"{n1}"
                      break
                  if not lanes:
                      continue
          
                  sh, sm = time_token_to_24h(m.group("s"))
                  eh, em = time_token_to_24h(m.group("e"))
                  st_utc = to_utc_local_eastern(local_date, sh, sm)
                  en_utc = to_utc_local_eastern(local_date, eh, em)
                  if en_utc <= st_utc:
                      en_utc += timedelta(days=1)
                  yield st_utc, en_utc, lanes

          def parse_pdf(url: str) -> List[Block]:
              r = requests.get(url, timeout=60)
              r.raise_for_status()
              blocks: List[Block] = []
              now_utc = datetime.now(timezone.utc)
              with pdfplumber.open(io.BytesIO(r.content)) as pdf:
                  for page in pdf.pages:
                      text = page.extract_text() or ""
                      header = next((ln for ln in text.splitlines() if "Pool Schedule for" in ln), "")
                      if not header:
                          continue
                      week_start_guess, _ = month_span_to_dates(header, now_utc)
                      while week_start_guess.weekday() != 0:
                          week_start_guess -= timedelta(days=1)
                      words = page.extract_words(keep_blank_chars=False, use_text_flow=True)
                      columns = group_by_day_columns(words)
                      for day_offset, day in enumerate(DAYS):
                          local_date = week_start_guess + timedelta(days=day_offset)
                          for st_utc, en_utc, label in extract_blocks_for_day(columns.get(day, []), local_date):
                              blocks.append(Block(start=st_utc, end=en_utc, lanes_label=label, source_url=url))
              return blocks

          def make_calendar(blocks: Iterable[Block]) -> Calendar:
              cal = Calendar()
              cal.add("prodid", "-//Brookline EKAC Lanes//bhs-pool-calendar//EN")
              cal.add("version", "2.0")
              cal.add("x-wr-calname", "Brookline EKAC Lap Lanes")
              cal.add("x-wr-timezone", "America/New_York")
              for b in blocks:
                  ev = Event()
                  ev.add("dtstart", b.start)
                  ev.add("dtend", b.end)
                  ev.add("summary", f"Lap lanes: {b.lanes_label.replace('-', '–')} open")
                  ev.add("location", "Evelyn Kirrane Aquatics Center, 60 Tappan St, Brookline, MA 02446")
                  ev.add("description", f"Source: {b.source_url}")
                  uid_raw = f"{b.start.isoformat()}|{b.end.isoformat()}|{b.lanes_label}"
                  ev.add("uid", f"ekac-{hashlib.sha1(uid_raw.encode('utf-8')).hexdigest()}@bhs-pool-calendar")
                  cal.add_component(ev)
              return cal

          def main() -> int:
              pdf_url = discover_latest_pdf()
              blocks = parse_pdf(pdf_url)
              os.makedirs("public", exist_ok=True)
              cal = make_calendar(blocks)
              with open("public/ekac.ics", "wb") as f:
                  f.write(cal.to_ical())
              print(f"Wrote public/ekac.ics with {len(blocks)} events from {pdf_url}")
              return 0

          if __name__ == "__main__":
              try:
                  raise SystemExit(main())
              except Exception as exc:
                  print(f"ERROR: {exc}", file=sys.stderr)
                  raise
          PY
          chmod +x app/build_calendar.py

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pdfplumber python-dateutil icalendar beautifulsoup4

      - name: Build calendar
        run: python app/build_calendar.py

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/deploy-pages@v4
