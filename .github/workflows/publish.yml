name: Publish EKAC lanes calendar

on:
  schedule:
    - cron: "10 9 * * *"   # ~05:10 ET daily (UTC-based)
  workflow_dispatch: {}

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Write scraper script
        run: |
          mkdir -p app public
          cat > app/build_calendar.py <<'PY'
          #!/usr/bin/env python3
          from __future__ import annotations

          import hashlib
          import io
          import os
          import re
          import sys
          from dataclasses import dataclass
          from datetime import datetime, timedelta, timezone
          from typing import Iterable, List, Tuple

          import pdfplumber
          import requests
          from bs4 import BeautifulSoup
          from dateutil import parser as dtparse
          from icalendar import Calendar, Event

          AQUATICS_URL = "https://www.brooklinerec.com/150/Aquatics-Center"
          FALLBACK_PDF = "https://www.brooklinerec.com/DocumentCenter/View/4404/Pool-Schedule?bidId="
          DAYS = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]

          @dataclass(frozen=True)
          class Block:
              start: datetime  # UTC
              end: datetime    # UTC
              lanes_label: str
              source_url: str

          def discover_latest_pdf() -> str:
              try:
                  resp = requests.get(AQUATICS_URL, timeout=30)
                  resp.raise_for_status()
                  soup = BeautifulSoup(resp.text, "html.parser")
                  for a in soup.find_all("a", href=True):
                      href = a["href"]
                      text = (a.get_text() or "").lower()
                      if ("/DocumentCenter/View/" in href) and ("pool" in text and "schedule" in text):
                          return requests.compat.urljoin(AQUATICS_URL, href)
                  for a in soup.find_all("a", href=True):
                      href = a["href"]
                      if "/DocumentCenter/View/" in href and "Pool" in href and "Schedule" in href:
                          return requests.compat.urljoin(AQUATICS_URL, href)
              except Exception:
                  pass
              return FALLBACK_PDF

          def month_span_to_dates(header: str, now_utc: datetime) -> Tuple[datetime, datetime]:
              m = re.search(r"Pool Schedule for\s+([A-Za-z]+)\s+(\d{1,2})\s*-\s*(\d{1,2})", header)
              if not m:
                  raise ValueError(f"Unrecognized header line: {header!r}")
              month, d1, d2 = m.group(1), int(m.group(2)), int(m.group(3))
              candidates = []
              for year in (now_utc.year - 1, now_utc.year, now_utc.year + 1):
                  s = dtparse.parse(f"{month} {d1}, {year}").date()
                  e = dtparse.parse(f"{month} {d2}, {year}").date()
                  candidates.append((s, e, abs((now_utc.date() - s).days)))
              s, e, _ = min(candidates, key=lambda t: t[2])
              return (
                  datetime(s.year, s.month, s.day, tzinfo=timezone.utc),
                  datetime(e.year, e.month, e.day, tzinfo=timezone.utc),
              )

          def to_utc_local_eastern(local_date: datetime, hh: int, mm: int) -> datetime:
              from zoneinfo import ZoneInfo
              eastern = ZoneInfo("America/New_York")
              local_dt = datetime(local_date.year, local_date.month, local_date.day, hh, mm, tzinfo=eastern)
              return local_dt.astimezone(timezone.utc)

          def time_token_to_24h(tstr: str) -> Tuple[int, int]:
              m = re.fullmatch(r"(\d{1,2}):(\d{2})([ap])", tstr)
              if not m:
                  raise ValueError(f"Bad time token: {tstr}")
              hh, mm, ap = int(m.group(1)), int(m.group(2)), m.group(3)
              if ap == "a":
                  hh = 0 if hh == 12 else hh
              else:
                  hh = 12 if hh == 12 else hh + 12
              return hh, mm

          def group_by_day_columns(words: List[dict]) -> dict[str, List[dict]]:
              headers: List[Tuple[str, float]] = []
              for w in words:
                  if w["text"] in DAYS:
                      headers.append((w["text"], (w["x0"] + w["x1"]) / 2.0))
              if len(headers) != 7:
                  raise ValueError("Failed to find Monday..Sunday headers")
              headers.sort(key=lambda t: t[1])
              bounds: List[Tuple[str, float, float]] = []
              for i, (_, xmid) in enumerate(headers):
                  left = -1e9 if i == 0 else (headers[i - 1][1] + xmid) / 2.0
                  right = 1e9 if i == 6 else (xmid + headers[i + 1][1]) / 2.0
                  bounds.append((DAYS[i], left, right))
              columns: dict[str, List[dict]] = {d: [] for d in DAYS}
              for w in words:
                  xmid = (w["x0"] + w["x1"]) / 2.0
                  for day, left, right in bounds:
                      if left <= xmid <= right:
                          columns[day].append(w)
                          break
              for d in DAYS:
                  columns[d].sort(key=lambda w: (w["top"], w["x0"]))
              return columns

          def extract_blocks_for_day(day_words: List[dict], local_date: datetime) -> Iterable[Tuple[datetime, datetime, str]]:
              time_re = re.compile(r"(\d{1,2}:\d{2}[ap])-(\d{1,2}:\d{2}[ap])$")
              lanes_re = re.compile(r"^\d+(?:-\d+)?$")
              tokens = [w["text"] for w in day_words]
              i = 0
              while i < len(tokens):
                  t = tokens[i]
                  m = time_re.fullmatch(t)
                  if m:
                      lanes_label = None
                      j = i + 1
                      while j < len(tokens):
                          nxt = tokens[j]
                          if nxt.upper() == "CLOSED":
                              break
                          if lanes_re.fullmatch(nxt):
                              lanes_label = nxt
                              break
                          j += 1
                      if lanes_label:
                          sh, sm = time_token_to_24h(m.group(1))
                          eh, em = time_token_to_24h(m.group(2))
                          st_utc = to_utc_local_eastern(local_date, sh, sm)
                          en_utc = to_utc_local_eastern(local_date, eh, em)
                          if en_utc <= st_utc:
                              en_utc += timedelta(days=1)
                          yield st_utc, en_utc, lanes_label
                          i = j + 1
                      else:
                          i += 1
                  else:
                      i += 1

          def parse_pdf(url: str) -> List[Block]:
              r = requests.get(url, timeout=60)
              r.raise_for_status()
              blocks: List[Block] = []
              now_utc = datetime.now(timezone.utc)
              with pdfplumber.open(io.BytesIO(r.content)) as pdf:
                  for page in pdf.pages:
                      text = page.extract_text() or ""
                      header = next((ln for ln in text.splitlines() if "Pool Schedule for" in ln), "")
                      if not header:
                          continue
                      week_start_guess, _ = month_span_to_dates(header, now_utc)
                      while week_start_guess.weekday() != 0:
                          week_start_guess -= timedelta(days=1)
                      words = page.extract_words(keep_blank_chars=False, use_text_flow=True)
                      columns = group_by_day_columns(words)
                      for day_offset, day in enumerate(DAYS):
                          local_date = week_start_guess + timedelta(days=day_offset)
                          for st_utc, en_utc, label in extract_blocks_for_day(columns.get(day, []), local_date):
                              blocks.append(Block(start=st_utc, end=en_utc, lanes_label=label, source_url=url))
              return blocks

          def make_calendar(blocks: Iterable[Block]) -> Calendar:
              cal = Calendar()
              cal.add("prodid", "-//Brookline EKAC Lanes//bhs-pool-calendar//EN")
              cal.add("version", "2.0")
              cal.add("x-wr-calname", "Brookline EKAC Lap Lanes")
              cal.add("x-wr-timezone", "America/New_York")
              for b in blocks:
                  ev = Event()
                  ev.add("dtstart", b.start)
                  ev.add("dtend", b.end)
                  ev.add("summary", f"Lap lanes: {b.lanes_label.replace('-', 'â€“')} open")
                  ev.add("location", "Evelyn Kirrane Aquatics Center, 60 Tappan St, Brookline, MA 02446")
                  ev.add("description", f"Source: {b.source_url}")
                  uid_raw = f"{b.start.isoformat()}|{b.end.isoformat()}|{b.lanes_label}"
                  ev.add("uid", f"ekac-{hashlib.sha1(uid_raw.encode('utf-8')).hexdigest()}@bhs-pool-calendar")
                  cal.add_component(ev)
              return cal

          def main() -> int:
              pdf_url = discover_latest_pdf()
              blocks = parse_pdf(pdf_url)
              os.makedirs("public", exist_ok=True)
              cal = make_calendar(blocks)
              with open("public/ekac.ics", "wb") as f:
                  f.write(cal.to_ical())
              print(f"Wrote public/ekac.ics with {len(blocks)} events from {pdf_url}")
              return 0

          if __name__ == "__main__":
              try:
                  raise SystemExit(main())
              except Exception as exc:
                  print(f"ERROR: {exc}", file=sys.stderr)
                  raise
          PY
          chmod +x app/build_calendar.py

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pdfplumber python-dateutil icalendar beautifulsoup4

      - name: Build calendar
        run: python app/build_calendar.py

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/deploy-pages@v4
